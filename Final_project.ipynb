{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_project.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YprzHzKAq0G5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   \n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LbiUAkmtAUJ"
      },
      "source": [
        "train_data = pd.read_csv(\"./data/train.csv\")\n",
        "test_data = pd.read_csv(\"./data/test.csv\")"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkAYFhrVf1Z7"
      },
      "source": [
        "# **2. Data cleanning** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N31oRz7Kg0js"
      },
      "source": [
        "def remove_URL(text):\n",
        "    text_new = re.sub(r'https?://\\S+|www\\.\\S+', r'', text)\n",
        "    # url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return text_new\n",
        "\n",
        "train_data['text'] = train_data['text'].apply(lambda x : remove_URL(x))\n",
        "# print(train_data['text'])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uSPgLX5ii-i"
      },
      "source": [
        "def remove_html(text):\n",
        "    # html = re.compile(r'<.*?>')\n",
        "    text_new = re.sub(r'<.*?>', r'', text)\n",
        "    return text_new\n",
        "\n",
        "train_data['text'] = train_data['text'].apply(lambda x : remove_html(x))"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k684n4WoopY"
      },
      "source": [
        "def remove_punct(text):\n",
        "    table=str.maketrans('','',string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "train_data['text'] = train_data['text'].apply(lambda x : remove_punct(x))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcr9Ru6d6PTa"
      },
      "source": [
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  \n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  \n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  \n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  \n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "train_data['text'] = train_data['text'].apply(lambda x: remove_emoji(x))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36R_n31EgEZl"
      },
      "source": [
        "# **3. Data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np9Bxl4WY2v4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()              \n",
        "tokenizer.fit_on_texts(train_data.text)   \n",
        "word_index = tokenizer.word_index "
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBSVbzQsdRa-"
      },
      "source": [
        "# print('Number of unique words:',len(word_index))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNz9GEcvdZBH"
      },
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(train_data.text)  \n",
        "MAX_LEN=20    \n",
        "training_padded = pad_sequences(training_sequences, \n",
        "                                   maxlen=MAX_LEN,          \n",
        "                                   padding='post',       \n",
        "                                   truncating='post')      "
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgzaPgaFhTou"
      },
      "source": [
        "embedding_dict={}\n",
        "\n",
        "with open('./glove.6B.100d.txt','r',encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values=line.split()\n",
        "        word=values[0]\n",
        "        vectors=np.asarray(values[1:],'float32')\n",
        "        embedding_dict[word]=vectors\n",
        "f.close()"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ygcUyEBhooJ",
        "outputId": "da89b244-4d5a-4104-9438-20b1f292c964"
      },
      "source": [
        "num_words = len(word_index)+1\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    if i < num_words:\n",
        "        embedding_vector = embedding_dict.get(word)  \n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18104/18104 [00:00<00:00, 457804.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18105, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URf2Ql4Ste-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28518ae8-da51-489d-8fdb-2f43ef67e3a2"
      },
      "source": [
        "print(training_padded)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 109 4493   20 ...    0    0    0]\n",
            " [ 179   41  218 ...    0    0    0]\n",
            " [  38 1694 1570 ...    3  651 1351]\n",
            " ...\n",
            " [3301 4485 6707 ...    0    0    0]\n",
            " [  75 1102   37 ... 2563  296    0]\n",
            " [   1  199   51 ...    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V85DQyUhSwV7"
      },
      "source": [
        "## **4. Build my model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVS1k8ZwGuXW"
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Embedding,Dense,Dropout,LSTM\n",
        "from keras import optimizers,initializers"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4_YmpK6GxmT"
      },
      "source": [
        "def create_model():\n",
        "    model = Sequential() \n",
        "    model.add(Embedding(input_dim=num_words,\n",
        "                        output_dim=100,\n",
        "                        embeddings_initializer=initializers.Constant(embedding_matrix), \n",
        "                        input_length=MAX_LEN,trainable=False))\n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(128, activation='sigmoid')) \n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(64, activation='sigmoid')) \n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(1, activation='sigmoid')) \n",
        "    model.compile(loss='binary_crossentropy',  \n",
        "                  optimizer='adam',              \n",
        "                  metrics=['accuracy'])          \n",
        "    return model"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFmecErxHVH3",
        "outputId": "024e981f-57c2-4cee-ca72-57a21a5a05a7"
      },
      "source": [
        "model=create_model()\n",
        "model.summary()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_246\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_246 (Embedding)    (None, 20, 100)           1810500   \n",
            "_________________________________________________________________\n",
            "dropout_410 (Dropout)        (None, 20, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_246 (LSTM)              (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dense_574 (Dense)            (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_411 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_575 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_412 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_576 (Dense)            (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,869,381\n",
            "Trainable params: 58,881\n",
            "Non-trainable params: 1,810,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rvZRnmeHYSn"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier \n",
        "from sklearn.model_selection import GridSearchCV \n",
        "model = KerasClassifier(build_fn=create_model, verbose=0) \n",
        "batch_size = [5, 10, 20, 50, 100] \n",
        "epochs = [5, 10, 15, 20, 35, 50] \n",
        "param_grid = dict(batch_size=batch_size, nb_epoch=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=1)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8lXhvnaHgX0"
      },
      "source": [
        "grid_result = grid.fit(training_padded, train_data['target'].values)\n",
        "results= pd.DataFrame(grid_result.cv_results_)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfcUvnLXG0AC",
        "outputId": "1dcf49ee-1d1c-4330-ae7c-b3f1de045929"
      },
      "source": [
        "print(\"Cross accuracy：\\n\", grid_result.best_score_)\n",
        "print(\"best parameter\\n\", grid_result.best_params_)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross accuracy：\n",
            " 0.7928552389144897\n",
            "best parameter\n",
            " {'batch_size': 20, 'nb_epoch': 35}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlMMNOAFbkR0"
      },
      "source": [
        "# **5. Baeline models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek4iwpaGS1bN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(training_padded, train_data['target'].values, test_size=0.2)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoWEwN5KTIYw",
        "outputId": "a14407d8-3608-42fc-ad87-7986c907e2c3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm,neighbors,neural_network,naive_bayes, ensemble\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import *\n",
        "\n",
        "\n",
        "model1= svm.SVC()\n",
        "model1.fit(X_train,y_train)\n",
        "predict1=model1.predict(X_test)\n",
        "\n",
        "model2=neighbors.KNeighborsClassifier()\n",
        "model2.fit(X_train,y_train)\n",
        "\n",
        "model3=neural_network.MLPClassifier(max_iter=1000)\n",
        "model3.fit(X_train,y_train)\n",
        "\n",
        "model4=naive_bayes.GaussianNB()\n",
        "model4.fit(X_train,y_train)\n",
        "\n",
        "model5=ensemble.RandomForestClassifier()\n",
        "model5.fit(X_train,y_train)\n",
        "\n",
        "model6=ensemble.GradientBoostingClassifier()\n",
        "model6.fit(X_train,y_train)\n",
        "\n",
        "print('Model 1 Accuracy:',model1.score(X_test, y_test))\n",
        "print('Model 2 Accuracy:',model2.score(X_test, y_test))\n",
        "print('Model 3 Accuracy:',model3.score(X_test, y_test))\n",
        "print('Model 4 Accuracy:',model4.score(X_test, y_test))\n",
        "print('Model 5 Accuracy:',model5.score(X_test, y_test))\n",
        "print('Model 6 Accuracy:',model6.score(X_test, y_test))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1 Accuracy: 0.5673013788575181\n",
            "Model 2 Accuracy: 0.582403151674327\n",
            "Model 3 Accuracy: 0.5384110308601444\n",
            "Model 4 Accuracy: 0.5331582403151675\n",
            "Model 5 Accuracy: 0.6815495732107683\n",
            "Model 6 Accuracy: 0.6631648063033486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ1DZcaJNYpw",
        "outputId": "16ae5018-cd1d-4ecb-e0ce-640f8e3e9521"
      },
      "source": [
        "submission = {}\n",
        "testing_sequences = tokenizer.texts_to_sequences(test_data.text)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "predictions = grid_result.predict(testing_padded)\n",
        "# submission = (predictions > 0.5).astype(int)\n",
        "test_data['target'] = pd.Series(predictions.reshape(1, -1)[0])\n",
        "test_data['target']"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "3258    1\n",
              "3259    1\n",
              "3260    0\n",
              "3261    0\n",
              "3262    0\n",
              "Name: target, Length: 3263, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p1lTgfh4RKP"
      },
      "source": [
        "submission = pd.concat([test_data['id'], test_data['target']], axis=1)\n",
        "submission.to_csv(\"submission.csv\", index=False, header=True)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08chAXCJIN27",
        "outputId": "bba555c5-4bb6-4581-d1e6-ba4ece51df23"
      },
      "source": [
        "print(submission)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         id  target\n",
            "0         0       1\n",
            "1         2       1\n",
            "2         3       1\n",
            "3         9       1\n",
            "4        11       1\n",
            "...     ...     ...\n",
            "3258  10861       1\n",
            "3259  10865       1\n",
            "3260  10868       0\n",
            "3261  10874       0\n",
            "3262  10875       0\n",
            "\n",
            "[3263 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}